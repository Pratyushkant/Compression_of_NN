{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7751f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "Device: cuda\n",
      "\n",
      "Loading CIFAR-10 data...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Training Modified SimpleCNN (FC1 & FC2 removed) ---\n",
      "Epoch 1/5: Loss=1.5779, Accuracy=42.67%\n",
      "Epoch 2/5: Loss=1.1963, Accuracy=57.31%\n",
      "Epoch 3/5: Loss=1.0274, Accuracy=64.22%\n",
      "Epoch 4/5: Loss=0.9307, Accuracy=67.72%\n",
      "Epoch 5/5: Loss=0.8613, Accuracy=69.98%\n",
      "\n",
      "Final Accuracy of Modified Model (FC1 & FC2 removed): 71.86%\n",
      "Total Parameters of Modified Model: 113,738\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Determine the device to use (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODIFIED SIMPLE CNN ARCHITECTURE (FC1 and FC2 Layers Removed)\n",
    "# ============================================================================\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Directly connect the output of conv3 (after pooling) to the final fc3 layer\n",
    "        # The output size of conv3 after 3 pooling layers (each reducing by factor of 2)\n",
    "        # from a 32x32 input is 32 / (2*2*2) = 4x4.\n",
    "        # So, the input features to fc3 will be 128 channels * 4 * 4.\n",
    "        self.fc3 = nn.Linear(128 * 4 * 4, num_classes)\n",
    "        \n",
    "        # Removed self.fc1, self.fc2, and self.dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten the output for the FC layer\n",
    "        x = x.view(x.size(0), -1) \n",
    "        \n",
    "        # Directly pass to the final classification layer\n",
    "        return self.fc3(x)\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING (CIFAR-10)\n",
    "# ============================================================================\n",
    "def load_cifar10_data(batch_size=128):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses CIFAR-10 dataset.\n",
    "    \"\"\"\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING AND EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "def train_model(model, trainloader, testloader, epochs=10, lr=0.001, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains the given PyTorch model.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct, total, loss_sum = 0, 0, 0.0\n",
    "        for inputs, targets in trainloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            loss_sum += loss.item()\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: Loss={loss_sum / len(trainloader):.4f}, Accuracy={100.*correct/total:.2f}%\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluates the given PyTorch model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    return 100. * correct / total\n",
    "\n",
    "# ============================================================================\n",
    "# PARAMETER COUNTING FUNCTIONS\n",
    "# ============================================================================\n",
    "def count_model_parameters(model):\n",
    "    \"\"\"Count total trainable parameters in a model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN SCRIPT EXECUTION (Modified)\n",
    "# ============================================================================\n",
    "\n",
    "def run_simplified_cnn_experiment():\n",
    "    \"\"\"\n",
    "    Runs the experiment with FC1 and FC2 layers removed.\n",
    "    \"\"\"\n",
    "    print(\"Loading CIFAR-10 data...\")\n",
    "    trainloader, testloader = load_cifar10_data()\n",
    "\n",
    "    # --- Step 1: Initialize and train the modified model ---\n",
    "    print(\"\\n--- Training Modified SimpleCNN (FC1 & FC2 removed) ---\")\n",
    "    \n",
    "    # Create an instance of the modified SimpleCNN\n",
    "    modified_model = SimpleCNN()\n",
    "    \n",
    "    # Train the modified model for 5 epochs, same as the original baseline\n",
    "    train_model(modified_model, trainloader, testloader, epochs=5, lr=0.001, verbose=True)\n",
    "    \n",
    "    # --- Step 2: Evaluate the modified model ---\n",
    "    final_accuracy = evaluate_model(modified_model, testloader)\n",
    "    total_params = count_model_parameters(modified_model)\n",
    "\n",
    "    print(f\"\\nFinal Accuracy of Modified Model (FC1 & FC2 removed): {final_accuracy:.2f}%\")\n",
    "    print(f\"Total Parameters of Modified Model: {total_params:,}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_simplified_cnn_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
